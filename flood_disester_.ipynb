{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flood disester .ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "otwjZobDqtLg"
      },
      "source": [
        "# Loading required libraries and functions\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "from keras import backend\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet import decode_predictions, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XR6ypLy9TqJ"
      },
      "source": [
        "!unzip '/content/data (1).zip' -d '/content'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y5-twM5OiTC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtg8w09GAUSH"
      },
      "source": [
        "# Loading data and preprocessing images according to mobilenet requirements\n",
        "# Creating batches of data\n",
        "\n",
        "labels = ['Flooding', 'No Flooding']\n",
        "train_path = '/content/data/train'\n",
        "valid_path = '/content/data/valid'\n",
        "test_path = '/content/data/test'\n",
        "\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    directory=train_path, target_size=(224,224), batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    directory=valid_path, target_size=(224,224), batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    directory=test_path, target_size=(224,224), batch_size=10, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKHoZ2q_AUbl"
      },
      "source": [
        "#Loading pre-trained lightweight mobilenet image classifier\n",
        "mobile = tf.keras.applications.mobilenet.MobileNet()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv4G4i6mAUeF"
      },
      "source": [
        "mobile.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsGYl6lAUgw"
      },
      "source": [
        "# Store all layers of the original mobilenet except the last 5 layers in variable x\n",
        "# There is no predefined logic behind this, it just gives the optimal results for this task\n",
        "# Also, we will be only training the last 5 layers of the mobilenet during finetuning as we want \n",
        "# it to keep all of the previously learned weights \n",
        "x = mobile.layers[-6].output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re7oSfIqJBob"
      },
      "source": [
        "\n",
        "# Create an output layer with binary output layer, as we want our model to be a binary classifier, \n",
        "# i.e. to classify flooding and no flooding\n",
        "output = Dense(units=2, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vmJkB0NJD-d"
      },
      "source": [
        "\n",
        "# Construct the new fine-tuned mode\n",
        "model = Model(inputs=mobile.input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLPyWFoxJF_w"
      },
      "source": [
        "\n",
        "# Freez weights of all the layers except for the last five layers in our new model, \n",
        "# meaning that only the last five layers of the model will be trained.\n",
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCRH3VcxJH_V"
      },
      "source": [
        "#model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e05Gjj7dJJ_0"
      },
      "source": [
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydCIPp7MJOhc"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "model.fit(x=train_batches,\n",
        "          steps_per_epoch=len(train_batches),\n",
        "          validation_data=valid_batches,\n",
        "          validation_steps=len(valid_batches),\n",
        "          epochs=10,\n",
        "          verbose=2\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4QbOUMxJTIM"
      },
      "source": [
        "# Saving and loading our trained for future use\n",
        "\n",
        "model.save(\"fine_tuned_flood_detection_model.model\")\n",
        "# model.load_weights('fine_tuned_flood_detection_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVvn43qbJpGg"
      },
      "source": [
        "# Make predictions and plot confusion matrix to look how well our model performed in classifying \n",
        "# flooding and no flooding images \n",
        "\n",
        "test_labels = test_batches.classes\n",
        "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)\n",
        "cm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
        "precision = precision_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
        "f1_score = f1_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
        "accuracy = accuracy_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfAVe6_BJybu"
      },
      "source": [
        "# Pring precision, F1 score and accuracy of our model\n",
        "print('Precision: ', precision)\n",
        "print('F1 Score: ', f1_score)\n",
        "print('Accuracy: ', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX6h18UUJ53e"
      },
      "source": [
        "# Confusion Matrix \n",
        "test_batches.class_indices\n",
        "cm_plot_labels = ['Flooding','No Flooding']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKaQ0a9yJ8td"
      },
      "source": [
        "# Prepare image for mobilenet prediction\n",
        "\n",
        "def preprocess_image(file):\n",
        "    img_path = '/content/'\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sv68TeVKTOX"
      },
      "source": [
        "# Display image which we want to predict\n",
        "from IPython.display import Image\n",
        "Image(filename='2.jpg', width=300,height=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxSB2_d3LHJd"
      },
      "source": [
        "# Preprocess image and make prediction\n",
        "\n",
        "preprocessed_image = preprocess_image('3.jpeg')\n",
        "predictions = model.predict(preprocessed_image)\n",
        "# Print predicted accuracy scores for both classes, i.e. (1) Flooding, (2) No Flooding\n",
        "#predictions\n",
        "# Get the maximum probability score for predicted class from predictions array\n",
        "result = np.argmax(predictions)\n",
        "# Print the predicted class label\n",
        "labels[result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6QuewSJLNz_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQgmAmgLQlJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPtB824OLXhB"
      },
      "source": [
        "import cv2\n",
        "CATEGORIES = ['Flooding', 'No Flooding']\n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/fine_tuned_flood_detection_model.model\")\n",
        "#prediction = model.predict('/content/3.jpeg')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDuVj8L2Okpx"
      },
      "source": [
        "preprocessed_image = preprocess_image('1.jpg')\n",
        "prediction = model.predict(preprocessed_image)\n",
        "print(CATEGORIES[int(prediction[0][0])])\n",
        "#result = np.argmax(prediction)\n",
        "# Print the predicted class label\n",
        "#labels[result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHNEG5RIQY8Y"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import load_model\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ovwvr5mSGpZ"
      },
      "source": [
        "# load the trained model and label binarizer from disk\n",
        "print(\"[INFO] loading model and label binarizer...\")\n",
        "model = load_model(\"/content/fine_tuned_flood_detection_model.model\")\n",
        "#lb = pickle.loads(open([\"label_bin\"], \"rb\").read())\n",
        "# initialize the image mean for mean subtraction along with the\n",
        "# predictions queue\n",
        "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
        "#Q = deque(maxlen[\"size\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w0qfqAeSk4s"
      },
      "source": [
        "vs = cv2.VideoCapture('/content/videoplayback.mp4')\n",
        "writer = None\n",
        "(W, H) = (None, None)\n",
        "# loop over frames from the video file stream\n",
        "while True:\n",
        "\t# read the next frame from the file\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\t# if the frame was not grabbed, then we have reached the end\n",
        "\t# of the stream\n",
        "\tif not grabbed:\n",
        "\t\tbreak\n",
        "\t# if the frame dimensions are empty, grab them\n",
        "\tif W is None or H is None:\n",
        "\t\t(H, W) = frame.shape[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubBWXK2YadRR"
      },
      "source": [
        "output = frame\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
        "frame -= mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKFvhwDkakRt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}